[{"content":" Some notes on the Paper \u0026ldquo;Psychological Aspects in Retrieval and Recommendation\u0026rdquo; published in SIGIR 2025, together with its slides available at: https://github.com/aisocietylab/Psy-IR-RecSys-SIGIR25/tree/main.\nThe tutorial focuses on three key psychological topics and sheds light on how they influence and manifest in the IR and RS ecosystem: cognitive architectures, cognitive effects and biases, and personality and affect.\nMotivation Understanding human cognition, decision-making processes, and psychological factors is important to enable user-centric retrieval and recommendation systems.\nUnderstanding whether these aspects are also present to some extent in the systems themselves (e.g.,in training data, ranking models, or outputs), or even integrating them in the systems on purpose, can inform the development of psychology-inspired systems.\nCognitive Architectures Cognitive architectures aim to model human-like cognitive processes such as perception, memory, learning, and problem-solving.\nThis paper covers several well-established cognitive architectures, discussing how they model human cognition and how they can be used to design adaptive, user-centric retrieval and recommendation techniques.\nFundamentals of Human Cognition Human Cognition: set of mental processes involved in acquiring, processing, storing and utilizing information, including perception, attention, memory, learning, reasoning, decision-making, problem-solving. \u0026ndash;\u0026gt; Core to how users interact with IR and RS, search perceive results and make choices in IR/RS contexts\nCognitive Load Cognitive Load Theory (CLT) (Sweller, 1988):\nUsers have limited working memory Performance depends on used capacity of working memory CLT defines three types of load:\nIntrinsic: inherent difficulty of task Extraneous: poor interface/irrelevant info Germane load: effort needed to build useful insights(\u0026ldquo;schemas in memory\u0026rdquo;) Taxonomy of Cognitive Architectures Major Cognitive Architectures Manifold cognitive architectures have been proposed to model human cognition\nRanging from symbolic to subsymbolic to hybrid and emergent approaches\nSome are particularly suited for modeling user behavior in IR/Rs:\nAdaptive Control of Thought-Rational (ACT-R). ACT-R models human cognition through memory modules and has been used to deliver personalized music recommendations, job recommendations, and model repeat music consumption. Soar, which models problem-solving and goal-driven learning, making it particularly useful for modeling long-term effects in RS. CLARION, a hybrid architectures that integrate symbolic reasoning with subsymbolic learning. Learning Intelligent Distribution Agent (LIDA) architecture can give insights into how attention and novelty influence human decision making and can be used to model serendipitous recommendations and content discovery processes, ensuring that users are exposed to a balanced mix of familiar and novel content. Pros and Cons Benefits:\nTypically, better interpretability - potential for explainability Allow for user-centric modeling Adaptive, cognitive plausible systems Challenges:\nScalability to large datasets and real-time systems Integration with advanced deep learning models Explainability vs. accuracy trade-offs Learning curve for researchers (interdisciplinarity!) Future Research Directions\nNeuro-symbolic IR and RS Hybrid models combining cognitive models + data-driven machine learning Real-time adaptation based on user cognitive signals Evaluation frameworks based on cognitive plausibility Potential for interpretable and adaptive IR/RS Cognitive Effects and Biases Human decision-making processes are strongly influenced by cognitive biases, which encompass both systematic individual deviations from rationality and societal prejudices that favor one group\u0026rsquo;s values, norms, and traditions over others.\nHuman decision making nowadays is often supported, or even replaced, by IR and RS. Given the prevalence of both cognitive biases as well as IR and RS technology in shaping human decisions, an investigation of their interaction is vital.\nCognitive Biases: Examples Feature-Positive Effect: Humans are better at realizing (and put more emphasis on) the presence of a stimulus rather than its absence\nIKEA Effect: The more effort a person invested in something, the more they will value it (Human desire to justify their efforts)\ne.g., Users tend to interact more with playlists they invested effort in, which can be used to increase user experience in sequential recommendation, where items present in the user\u0026rsquo;s playlists can serve as anchors to retain user engagement within the current listening session. (Social/Cultural) Homophily: Humans tend to associate and form connections with others who have similar characteristics (e.g., age, culture, or religion) more often than with people who have different traits\ne.g., Users with a specific trait (e.g., country, culture, or social group) may prefer content created by producers with the same trait (e.g., domestic vs. foreign music consumption) Conformity Bias: Tendency of individuals to align their beliefs, behaviors, and actions with those of a group, often disregarding their own independent judgment\ne.g., Users are more likely to click on an item if they see that many other users clicked on it Declinism: The perception that the world or society is declining, i.e., things get worse over time. Partly the result of rosy retrospection — humans’ tendency to remember the past as more positive as it actually was.\ne.g., Can these models be used to adjust outcomes, to counteract (or amplify) declinism? Primacy/Recency Effects, Position Bias: Human tendency to easier recall first and last items from a sequence as opposed to the items from the middle of the sequence\ne.g., Users are more likely to interact with items appearing at the beginning (primacy effect) and at the end (recency effect) of a list of recommendations or retrieved documents e.g., Can we counteract this effect by algorithmic in-processing or post-processing techniques (e.g. reranking)? Halo and Horn Effects: An individual’s perception of a single attribute (positive or negative) influences their opinion on other unrelated attributes\ne.g., Visual appeal of the presentation of (some) search results can influence clicking/consumption behavior Conclusions and Open Challenges Strong evidence of various cognitive biases in retrieval and recommendation processes\nMost studies face several limitations (e.g., only single or few domains, standard top-N recommendation scenario, ignoring confounding factors)\nHow to (mathematically) formalize accurate models of cognitive biases?\nWhich CoBis are intertwined and how does their entanglement manifest?\nWhich CoBis are important for different stakeholders?\nWhat role does the user interface play?\nHow do CoBis manifest in other retrieval and recommendation tasks and domains, e.g., sequential recommendation; video, travel, people?\nNeed a holistic discussion of both negative and positive effects of cognitive biases, and for new approaches to algorithmic decision making that mitigate the former while leveraging the latter.\nPersonality and Affect The user enters the interaction with the system with certain preferences, expectations, and experiences a level of satisfaction with the results. Several psychological constructs are related to these aspects of IR and RS.\nStates vs. Traits Personality and Emotions Mood: no particular trigger, can be positive/negative Emotions: can be triggered Emotions vs mood vs sentiment Emotion:\nbrief in duration consist of a coordinated set of responses (verbal, physiological, behavioral, and neural mechanisms) triggered Mood:\nlast longer less intense than emotions no trigger Sentiment\ntowards an object positive/negative Models of Emotions Emotions are complex human experiences and will evolve over time. Here just discuss simple models that easy to be incorporated in computers: basic emotions and a dimensional model.\nBasic Emotions Discrete classes model Ekman definition (6 + neutral): happiness, anger, fear, sadness, disgust, surprise Dimensional model of emotions Includes three continuous dimensions Valance/Pleasure (positive-negative) Arousal (high-low) Dominance (high-low) How to measure emotions Questionnaires Multimodal prediction (affective computing): modalities includes audio, language, visual, and physiology Emotions in RS and IR For recommendation system:\nEducational field match task/lesson difficulty to stress Emotions as context recommendations based on current emotions Emotion as feedback Group settings: emotional contagion For information retrieval, the emotions reframe the IR problem towards emotional relevance, ot just topical relevance\nPersonality models Personality accounts for individual differences ( = explains the variance in users) in our enduring emotional, interpersonal, experiential, attitudinal, and motivational styles\nThe Five Factor Model (Big 5): - Extraversion, Agreeableness, Conscientousness, Neuroticism (inverse = Emotional Stability), Openness (to new experiences)\nHow to measure personality? Questionnaires: lengthy, time consuming, intrusive\nNEO-PI-R: 240 items IPIP-50 BFI: 44 items TIPI: 10 items Inference from digital traces\nDigital traces: such as instagram, twitter, eye tracking data, brainwaves, physiological sensors pretrained models ethical issues Personality in Recommender Systems Cold-start problem: user-user similarity based on personality Diversity: Personality-based diversity adaptation Cross-domain recommendations: personality-based profiles in different domains Group recommender systems: Combining assertiveness and cooperativeness into the aggregation function Social media: followee recommendations Personality in Information Retrieval Few studies: mainly the personality of the system not the user Lots of opportunities Open Challenges Data acquisition (technical, legal, and ethical aspects), in particular regarding sensitive user traits. Improving the communication between the relevant research communities, including computer science, artificial intelligence, psychology, and sociology, in order to foster interdisciplinarity. ","permalink":"https://yningg.github.io/Blogs/posts/research/psychological_aspects/","summary":"\u003cblockquote\u003e\n\u003cp\u003eSome notes on the Paper \u0026ldquo;Psychological Aspects in Retrieval and Recommendation\u0026rdquo; published in SIGIR 2025, together with its slides available at: \u003ca href=\"https://github.com/aisocietylab/Psy-IR-RecSys-SIGIR25/tree/main\"\u003ehttps://github.com/aisocietylab/Psy-IR-RecSys-SIGIR25/tree/main\u003c/a\u003e.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eThe tutorial focuses on three key psychological topics and sheds light on how they influence and manifest in the IR and RS ecosystem: \u003cem\u003ecognitive architectures, cognitive effects and biases, and personality and affect\u003c/em\u003e.\u003c/p\u003e\n\u003ch2 id=\"motivation\"\u003eMotivation\u003c/h2\u003e\n\u003cp\u003eUnderstanding human cognition, decision-making processes, and psychological factors is important to \u003cstrong\u003eenable user-centric retrieval and recommendation systems\u003c/strong\u003e.\u003c/p\u003e","title":"Psychological Aspects in Retrieval and Recommendation"},{"content":" Here are just some notes taken while I was reading.\nRecently, some research has suggested that LLMs may even be able to simulate human psychology and can therefore replace human participants in psychological studies. We caution against this approach.\nFirst, we provide conceptual arguments against the hypothesis that LLMs simulate human psychology. We then present empiric evidence illustrating our arguments by demonstrating that slight changes to wording that correspond to large changes in meaning lead to notable discrepancies between LLMs\u0026rsquo; and human responses, even for the recent CENTAUR model that was specifically fine-tuned on psychological responses. Additionally, different LLMs show very different responses to novel items, further illustrating their lack of reliability. We conclude that LLMs do not simulate human psychology and recommend that psychological researchers should treat LLMs as useful but fundamentally unreliable tools that need to be validated against human responses for every new application.\nIntroduction The core function of any LLM is to simply predict the probability of each possible next word (more precisely: the next token), randomly select the next word according to the predicted probabilities, and continue until all desired text is generated\u0026ndash;with no explicit regard for meaning or truth.\nTask that particularly related to psychological science: simulating human participants\u0026rsquo; responses and thus reducing or potentially eliminating the need for such participants.\nThe structure of a prompt\nA description of a person or a certain participant group the LLM is supposed to simulate (e.g., US American women over 40) A stimulus, such as a vignette The questionnaire the simulated participants are supposed to answer LLMs can, fundamentally, not simulate human psychology when dealing with novel scenarios that go too far beyond the LLMs training data.\nCritiques of LLMs as Simulators of Human Psychology Non-Human Reactions to Instructions: LLMs do not always react to instructions as intended\nZhu et al. [2024] empirically investigated LLMs as user simulations in recommender systems and found that recommendations only became accurate if the prompt contained a lot of information about the target user whereas less extensive prompting yielded inaccurate recommendations. Garcia et al. [2024] revealed that LLM moral judgments shifted more dramatically than human judgments depending on framing of moral scenarios. Wang et al. [2025] argue that the textual descriptions in typical prompts are too simplistic to accurately describe a human persona Inconsistency Across Simulations:\nAssigning human-like identities to LLMs does not lead to consistent human-like behavior Behaviors are highly sensitive to prompt formulations and model architectures Inability to Capture Human Diversity: LLMs are unable to reproduce the variance and diversity of human responses, even if prompted with different personas\nBiases of LLMs: biases tend to be different from human biases because training data is not representative of human diversity\n\u0026ldquo;Hallucinations\u0026rdquo;: Multiple authors report the tendency of LLMs to \u0026ldquo;hallucinate\u0026rdquo;, meaning the generation of factually incorrect or fictional content that appears superficially convincing\na simple explanation is that there is no mechanism inside an LLM that would distinguish between fact or fiction Theoretical Arguments:\n[Van Rooij et al., 2024] have provided a mathematical proof that it is computationally infeasible to find a computational model (such as an LLM) that responds like humans across all possible inputs, just based on observations\nThe training data containing examples of human-like responses to psychological stimuli does not imply that the trained LLM will also respond human-like to new stimuli – only that the text output will look superficially similar.\nDemonstrations of the Limitations of LLMs We test whether LLMs simulate human psychology when items are re-worded.\nHow can LLMs Support Psychological Research? We recommend that psychologists should refrain from using LLMs as participants for psychological studies.\nLLMs may be useful in other ways in psychological research, for example as tools for brainstorming, pilot testing, and refining experimental materials, perhaps even automating single, well-validated steps of data annotation. Crucially, however, researchers should remain able to validate all LLM outputs - and this is not possible if the LLMs produce the primary research data.\n","permalink":"https://yningg.github.io/Blogs/posts/research/llm_psychology/","summary":"\u003cblockquote\u003e\n\u003cp\u003eHere are just some notes taken while I was reading.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eRecently, some research has suggested that LLMs may even be able to simulate human psychology and can therefore replace human participants in psychological studies. We caution against this approach.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eFirst, we provide \u003cstrong\u003econceptual arguments\u003c/strong\u003e against the hypothesis that LLMs simulate human psychology.\u003c/li\u003e\n\u003cli\u003eWe then present empiric evidence illustrating our arguments by demonstrating that \u003cu\u003eslight changes to wording that correspond to large changes in meaning lead to notable discrepancies between LLMs\u0026rsquo; and human responses\u003c/u\u003e, even for the recent CENTAUR model that was specifically fine-tuned on psychological responses.\u003c/li\u003e\n\u003cli\u003eAdditionally, different LLMs show very different responses to novel items, further illustrating their \u003cstrong\u003elack of reliability\u003c/strong\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWe conclude that \u003cstrong\u003eLLMs do not simulate human psychology\u003c/strong\u003e and recommend that psychological researchers should \u003cstrong\u003etreat LLMs as useful but fundamentally unreliable tools\u003c/strong\u003e that need to be validated against human responses for every new application.\u003c/p\u003e","title":"Large Language Models Do Not Simulate Human Psychology"},{"content":"阅读时间：2025-06-12 \u0026ndash;\u0026gt; 2025-06-25\n原文摘录 \u0026ldquo;是吗？\u0026ldquo;我笑起来，摇了摇头，\u0026ldquo;那你打算靠什么，\u0026lsquo;计数器\u0026rsquo;?\u0026rdquo;\n\u0026ldquo;是卡列尔，不是\u0026rsquo;计数器\u0026rsquo;!\u0026ldquo;外星小蜥蜴摇起脑袋，\u0026quot;\u0026lsquo;计数器\u0026rsquo;这个词有侮辱性，彼得。\u0026rdquo;\n\u0026ldquo;为什么？这个词不是我们发明的，其他种族也是这么叫你们的。\u0026rdquo;\n\u0026ldquo;它们还管人类叫\u0026rsquo;马车夫\u0026rsquo;呢。\u0026ldquo;外星小蜥蜴用短短的爪子指着我说，\u0026ldquo;彼得，用单一的功能指代别人，这是贴标签！对于弱小的种族来说，这是活命方式，也是诅咒。那些无法跳出自然属性框架的种族，永远都是奴仆！\u0026rdquo;\n如果更深入地分析人类社会，可以举这么个例子：父母有权指导自己的孩子向某个他们觉得有前景的方向发展。我们把有绝对音感的孩子培养成音乐家；把身姿轻盈的女孩培养成芭蕾舞演员。我们有权这么做，他们是我们的孩子，而且我们通常更有远见，知道哪条道路能让他们的人生更加成功。\n但强大种族不是我们的父母。太空马车夫的角色是几十年前被强加给我们的，那不是人类的梦想。\n若是人类父母出于个人需求来培养自己那可怜的孩子，我们会怎么说？如果他们把肌肉发达的男孩培养成伐木工，把纤柔瘦小的男孩培养成烟囱清扫工，并且完全剥夺孩子们选择自己人生道路的可能性，我们会怎么看待这些父母？人类文明的根本始终在于灵活性和普适性，这一点不仅适用于社会层面，在每个独立个体身上也都有体现。\n在空间内部穿梭的能力，给了人类一种强大的错觉，唤醒了人类虚幻的希望，让我们开始穷兵黩武。而我们本应该悄悄地、恭顺地去掌握整个宇宙的全貌，去了解那些我们并不需要占领的星球。人类的确还是孩子，这不是一句文字游戏，而是事实。我们在深不可测的天穹下、在黑暗无边的深渊中长大。每个漫漫长夜中，我们都在巴掌大的、扁平得像张桌子样的地球上跌跌撞撞。众星就在我们头顶闪耀，那么令人向往，又那么遥不可及。但我们却想方设法触摸到了星星。太早，还太早了。我们过早地触到了那些诱人的星星。\n人类的双手就这样被寒冰包裹的星星灼伤了。\n星星是冰冷的玩具，不是你我掌中之物。\n但我们又拒绝承认自己的力不从心，盲目相信自己的伟大，为拥有全宇宙最快的飞船而沾沾自喜……\n也就是说，你们是迁徙到了这里，几何学家。你们从那些试图将\u0026quot;友谊\u0026quot;强加于你们的种族手中逃脱了，你们把一整个星系都搬走了，连同母星、小人族和软族的星球一起。但你们还是不肯消停。你们做\u0026quot;善事\u0026quot;的执念根深蒂固。\n但为什么，为什么你们的善意总要以这种方式体现？\n我们也可以走这条路。但终点只能是一个理性、正确但伪善的天堂吗？我在这里遇到的一切都如此熟悉，一切都属于一个名叫乌托邦的美梦仓库﹣﹣整洁的城市、简陋的苦行僧生活、带领一代代人走向幸福的智慧导师，与其他种族的\u0026quot;友谊\u0026rdquo;……这一切也都曾是我们的梦想。\n如果这条路不能通向正确的结局，我该如何选择呢？\n是选择几何学家坚定的梦想？\n还是选择银河委员会邪恶的实用主义？\n或者暗影世界冷漠的自由？\n当你只有两个选择的时候，总是会指望第三条出路。\n但只有当童话里排行第三的小儿子战胜恶龙之后，第三个愿望才能实现。\n无论是在不自由的世界、铁律森森的世界，还是自由无度的无政府主义世界，人都注定会受到伤害。他们失去、追寻、犯错，不断遭遇痛苦，不断经受苦难。我需要的东西，没有人能给予我。我要的是一个天堂，而天堂并不存在。\n不能让人类拥有这样的自由。我们不能把决定权交给潜意识，交给自己颅底那一小团缥缈的思绪。**我们早就懂得了不能随心所欲，而要做应该做的事，这样才能找到自己真正的自由。**跟绝对自由的暗影世界比起来，甚至完全奴隶化的几何学家世界里都有更多通往真正自由的密道。因为随心所欲，就是真正的奴役。\n自己对自己的奴役。\n","permalink":"https://yningg.github.io/Blogs/posts/books/starstoy/","summary":"\u003cp\u003e阅读时间：2025-06-12 \u0026ndash;\u0026gt; 2025-06-25\u003c/p\u003e\n\u003ch2 id=\"原文摘录\"\u003e原文摘录\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u0026ldquo;是吗？\u0026ldquo;我笑起来，摇了摇头，\u0026ldquo;那你打算靠什么，\u0026lsquo;计数器\u0026rsquo;?\u0026rdquo;\u003c/p\u003e\n\u003cp\u003e\u0026ldquo;是卡列尔，不是\u0026rsquo;计数器\u0026rsquo;!\u0026ldquo;外星小蜥蜴摇起脑袋，\u0026quot;\u0026lsquo;计数器\u0026rsquo;这个词有侮辱性，彼得。\u0026rdquo;\u003c/p\u003e\n\u003cp\u003e\u0026ldquo;为什么？这个词不是我们发明的，其他种族也是这么叫你们的。\u0026rdquo;\u003c/p\u003e\n\u003cp\u003e\u0026ldquo;它们还管人类叫\u0026rsquo;马车夫\u0026rsquo;呢。\u0026ldquo;外星小蜥蜴用短短的爪子指着我说，\u0026ldquo;彼得，\u003cstrong\u003e用单一的功能指代别人，这是贴标签！对于弱小的种族来说，这是活命方式，也是诅咒。那些无法跳出自然属性框架的种族，永远都是奴仆！\u003c/strong\u003e\u0026rdquo;\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cblockquote\u003e\n\u003cp\u003e如果更深入地分析人类社会，可以举这么个例子：父母有权指导自己的孩子向某个他们觉得有前景的方向发展。我们把有绝对音感的孩子培养成音乐家；把身姿轻盈的女孩培养成芭蕾舞演员。我们有权这么做，他们是我们的孩子，而且我们通常更有远见，知道哪条道路能让他们的人生更加成功。\u003c/p\u003e\n\u003cp\u003e但强大种族不是我们的父母。太空马车夫的角色是几十年前被强加给我们的，那不是人类的梦想。\u003c/p\u003e\n\u003cp\u003e若是人类父母出于个人需求来培养自己那可怜的孩子，我们会怎么说？如果他们把肌肉发达的男孩培养成伐木工，把纤柔瘦小的男孩培养成烟囱清扫工，\u003cstrong\u003e并且完全剥夺孩子们选择自己人生道路的可能性\u003c/strong\u003e，我们会怎么看待这些父母？\u003cstrong\u003e人类文明的根本始终在于灵活性和普适性，这一点不仅适用于社会层面，在每个独立个体身上也都有体现\u003c/strong\u003e。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cblockquote\u003e\n\u003cp\u003e在空间内部穿梭的能力，给了人类一种强大的错觉，唤醒了人类虚幻的希望，让我们开始穷兵黩武。而我们本应该悄悄地、恭顺地去掌握整个宇宙的全貌，去了解那些我们并不需要占领的星球。人类的确还是孩子，这不是一句文字游戏，而是事实。我们在深不可测的天穹下、在黑暗无边的深渊中长大。每个漫漫长夜中，我们都在巴掌大的、扁平得像张桌子样的地球上跌跌撞撞。众星就在我们头顶闪耀，那么令人向往，又那么遥不可及。但我们却想方设法触摸到了星星。太早，还太早了。我们过早地触到了那些诱人的星星。\u003c/p\u003e\n\u003cp\u003e人类的双手就这样被寒冰包裹的星星灼伤了。\u003c/p\u003e\n\u003cp\u003e星星是冰冷的玩具，不是你我掌中之物。\u003c/p\u003e\n\u003cp\u003e但我们又拒绝承认自己的力不从心，盲目相信自己的伟大，为拥有全宇宙最快的飞船而沾沾自喜……\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cblockquote\u003e\n\u003cp\u003e也就是说，你们是迁徙到了这里，几何学家。你们从那些试图将\u0026quot;友谊\u0026quot;强加于你们的种族手中逃脱了，你们把一整个星系都搬走了，连同母星、小人族和软族的星球一起。但你们还是不肯消停。你们做\u0026quot;善事\u0026quot;的执念根深蒂固。\u003c/p\u003e\n\u003cp\u003e但为什么，为什么你们的善意总要以这种方式体现？\u003c/p\u003e\n\u003cp\u003e我们也可以走这条路。但终点只能是一个理性、正确但伪善的天堂吗？我在这里遇到的一切都如此熟悉，一切都属于一个名叫乌托邦的美梦仓库﹣﹣整洁的城市、简陋的苦行僧生活、带领一代代人走向幸福的智慧导师，与其他种族的\u0026quot;友谊\u0026rdquo;……这一切也都曾是我们的梦想。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cblockquote\u003e\n\u003cp\u003e如果这条路不能通向正确的结局，我该如何选择呢？\u003c/p\u003e\n\u003cp\u003e是选择几何学家坚定的梦想？\u003c/p\u003e\n\u003cp\u003e还是选择银河委员会邪恶的实用主义？\u003c/p\u003e\n\u003cp\u003e或者暗影世界冷漠的自由？\u003c/p\u003e\n\u003cp\u003e当你只有两个选择的时候，总是会指望第三条出路。\u003c/p\u003e\n\u003cp\u003e但只有当童话里排行第三的小儿子战胜恶龙之后，第三个愿望才能实现。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e无论是在不自由的世界、铁律森森的世界，还是自由无度的无政府主义世界，人都注定会受到伤害。他们失去、追寻、犯错，不断遭遇痛苦，不断经受苦难。我需要的东西，没有人能给予我。我要的是一个天堂，而天堂并不存在。\u003c/strong\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cblockquote\u003e\n\u003cp\u003e不能让人类拥有这样的自由。我们不能把决定权交给潜意识，交给自己颅底那一小团缥缈的思绪。**我们早就懂得了不能随心所欲，而要做应该做的事，这样才能找到自己真正的自由。**跟绝对自由的暗影世界比起来，甚至完全奴隶化的几何学家世界里都有更多通往真正自由的密道。\u003cstrong\u003e因为随心所欲，就是真正的奴役。\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e自己对自己的奴役。\u003c/strong\u003e\u003c/p\u003e\n\u003c/blockquote\u003e","title":"Reading Notes: 《星星是冰冷的玩具》"},{"content":"(Left appox. 3 papers to be updated in recent days)\nHere is a literature note on selected recent advancements in sentiment analysis techniques. The papers, published between 2024 and 2025 to date, all involve the application and/or discussion of LLMs in sentiment analysis tasks.\nTaxonomy of Sentiment Analysis Techniques Here I combine the taxonomies adopted in [2] and [6] to involve all mentioned sentiment analysis techniques.\nLexicon-based Methods Possible to measure gradations in sentiment More intrinsically suited to types of questions social scientists often ask, for example: Trends over time in average sentiment across large quantities of texts Whether one group of texts is more negative than another Traditional Machine Learning Models (e.g., Naive Bayes, Support Vector Machines (SVM)) Deep Learning Models (e.g., Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs)) Can learn hierarchical and sequential patterns in text, more suitable for sentiment analysis on informal social media platforms Appealing for domain-specific applications Performance degrades rapidly when methods are applied to other domains Often require large labeled datasets and computational resources Transformer-based Architectures (e.g., BERT, RoBERTa, and GPT) Can address challenges specific to Twitter, including brevity, mixed sentiments, and multilingual content Have high computational cost and require domain-specific adaptation Have built-in bias even without domain-specific fine-tuning. Even explicitly de-biased LLMs continue to reflect pernicious biases. Supervised/Fine-tuned LLMs Pros: require fewer labeled samples Cons: May represent \u0026ldquo;catastrophic forgetting\u0026rdquo;, in which fine-tuning a general model for the sentiment analysis task risks losing many of the strengths of the pre-trained model There are often unexpected (and unnoticed) pitfalls in trying to keep the training, validation, and application steps of the machine learning model separate, which may invalidate findings Comparing to the supervised methods, unsupervised methods (i.e., Lexicon-based methods and unsupervised learning methods) are more domain-independent.\nPaper 1: Unraveling media perspectives: a comprehensive methodology combining large language models, topic modeling, sentiment analysis, and ontology learning to analyse media bias Compare the performance of RoBERTa and spaCy\nRoBERTa: a powerful, pre-trained transformer-based language model that consistently achieves exceptional results across diverse NLP tasks, including sentiment analysis. spaCy: a versatile and widely used tool for natural language processing, and needs significantly less resources than transformers like RoBERTa Justification for minimal preprocessing dataset: minimal or no preprocessing yielded the best results for transformer models, depending on the specific dataset and transformer model used. In this context, minimal preprocessing refers to removing stopwords or converting text to lowercase.\nNonetheless, two optional preprocessing steps to increase the quality of results are recommended.\nExcluding non-English texts: this can increase the quality of results and ensure human understanding. Transformer models tend to perform best within the English language. Remove all text unrelated to the article’s topic: this can reduce the chance of topics being formed based on information that is not related to the actual topic of the article. Elements to be removed depend on the data source. E.g., advertisements, sections with related articles, and metadata about the article, like author and date in the text body. Paper 2: The advantages of lexicon-based sentiment analysis in an age of machine learning Many of automated methods share three important characteristics that limit their usefulness for general social science applications:\nInnovations in sentiment analysis have often been narrowly application- and domain-specific, which makes them unsuitable for comparisons across applications Most methods pay little or no attention to identifying a baseline or reference point. Many methods are unable to identify sentiment strength The reduction of sentiment to a binary classification–positive or negative only–risks drawing the wrong conclusions about patterns and trends in sentiment. (Another reason to adopt lexicon-based method) Being able to understand how a sentiment analysis method arrives at its assessment is often crucial in social science applications. However, many the machine learning approaches are black-box, or provide outputs such as feature weights that are almost impossible to interpret for human observers. Although it is possible to query LLMs for the \u0026ldquo;reasoning\u0026rdquo; behind a sentiment classification, their nature as \u0026ldquo;stochastic parrots\u0026rdquo; means that such reasoning cannot be relied upon.\nMultiLexScaled: a lexicon-based method that proposed in this paper\nWorking principle：average scores across eight widely used sentiment dictionaries Benefits: does not require any knowledge about the contents of the texts to be coded Paper 3: Weakly Supervised Deep Learning for Arabic Tweet Sentiment Analysis on Education Reforms: Leveraging Pre-Trained Models and LLMs With Snorkel Preprocessing of tweet dataset: removing non-essential elements, such as emojis, hashtags, @mentions, URLs, characters outside the Arabic alphabet, retweet indicators, duplicated tweets, letter repetitions, stop words, punctuation marks, numerical digits, and redundant spacing.\nPrompt Engineering: use LangChain framework to construct tailored instructions that guide the LLM in its sentiment classification task. Prompts included a task description,detailed instructions, and an expected output format.\nSystem = You are a helpful assistant working in the fields of Artificial Intelligence. You always respond in a professionally precise and accurate manner. Your answers and responds are always as short and as informative as possible. You are, also, honest and respond with (I don\u0026rsquo;t know.) in case you don\u0026rsquo;t have a clear answer. question = What is sentiment classification in NLP?\ninstructions = In the NLP task of sentiment classification, we try to label a piece of text as follows: 1. positive: if it has or contains a positive tone or lexicons.2. negative: if it has or contains a negative tone or lexicons.3. neutral: otherwise.You will be given a piece of text delimited by three hashs, label it based on the 3 classes above. ### {Text} ###\nOutput = \u0026ldquo;prediction\u0026rdquo;: string // The prediction of the included piece of text. Return only one of the following classes (positive, negative, neutral).\nPaper 4: GPT is an effective tool for multilingual psychological text analysis The social and behavioral sciences have been increasingly using automated text analysis to measure psychological constructs in text.\nGPT performed much better than English-language dictionary analysis at detecting psychological constructs. GPT performed nearly as well as, and sometimes better than, several top-performing fine-tuned machine learning models. Detailed results Sentiment: Even the oldest GPT model we analyzed, GPT-3.5Turbo, achieved good performance at predicting human ratings in both English Discrete Emotions: all versions of GPT had high agreement with humans in both English and Indonesian Offensiveness: We found high agreement between all versions of GPT and human ratings for English abd Turkish Sentiment and Discrete Emotions Measured on a Continuous Scale: GPT is capable of accurately detecting psychological constructs in text, regardless of the format of the ratings or the type of text GPT appears to be far more effective at detecting manually annotated sentiment and discrete emotions than common dictionary-based methods that are very popular in psychology and the social sciences Different versions of GPT provide very similar (albeit not exact) output for text analysis problems Analyses using GPT may potentially lead to very different conclusions than analyses using dictionary methods Moral Foundation: GPT may struggle more with more complex or difficult-to-define constructs Test–Retest Reliability of GPT:\nRunning GPT at separate times yields extremely high reliability when compared to traditional standards This suggests that GPT provides extremely reliable results even when the prompt is asked in a different language Paper 5: A Comparative Sentiment Analysis of Greek Clinical Conversations Using BERT, RoBERTa, GPT-2, and XLNet The categorization of utterances is as follows:\nMarked as positive when positive sentiments were expressed, such as satisfaction, relief, happiness, admiration, or gratitude. Marked as negative when negative sentiments are included, such as anger, pain, anxiety, etc. If an utterance lacks emotional expression or provides factual information, it is categorized as neutral sentiment. In the neutral category were also included general inquiries or educational information expressed by the clinicians to inform patients regarding their health condition. Paper 6: Sentiment Analysis of Twitter Data Using NLP Models: A Comprehensive Review Conducting sentiment analysis on Twitter data is notably complex for the following reasons:\nThe informal nature of the language used: tweets often contain slang, abbreviations, misspellings, emojis, hashtags, and context-dependent phrases, all of which add layers of complexity to the analysis. Twitter data is rife with phenomena such as sarcasm, irony, and ambiguous expressions that challenge even advanced NLP systems. Summary of the usage of GPT models Summary of the usage of BERT model Summary of the usage of RoBERTa model Overview of NLP models applied in sentiment analysis (Not only limited to Twitter datasets) Comparative analysis of model performance\nTransformer-based models, such as BERT, RoBERTa, and GPT variations, consistently exhibit superior performance BERT performs exceptionally well on tasks involving complex sentence structures RoBERTa often outperforms its predecessor, particularly in multi-class sentiment classification and domain-specific tasks, due to its enhanced training processes and larger training datasets GPT models, especially GPT-3 and GPT-3.5, show strong results in generating human-like text and handling nuanced context, although they sometimes require more data and fine-tuning for optimal sentiment analysis performance Traditional deep learning models remain effective for sequential data but often fall short compared to transformer-based architectures in understanding deeper contextual relationships The impact of pre-processing techniques Studies have shown that basic pre-processing methods help improve data quality and model interpretability.\nThe following techniques are applied to Twitter sentiment analysis.\nTokenization: critical for managing hashtags, mentions, and punctuation effectively. Can use methods like WordPiece or Byte Pair Encoding (BPE) Emoji and Hashtag Handling: convert emojis into textual equivalents (e.g., → happy) and split hashtags into component words (e.g., #HappyDay → Happy Day) Noise removal: includes eliminating retweets, URLs, mentions, and irrelevant symbols Stopword Removal: filters out common words (e.g., and, the) that do not carry significant sentiment information Normalization processes*: such as standardizing abbreviations, lowercase text, and handling elongated words (e.g., \u0026ldquo;cooool\u0026rdquo; \u0026ldquo;cool\u0026rdquo;), ensure uniformity in the dataset. Data Balancing: techniques such as oversampling, undersampling, or synthetic data generation are used to address class imbalance issues. In some cases, advanced techniques such as back-translation and synonym replacement are employed for data augmentation, enhancing model robustness.\nChallenges\nThe difficulty in detecting nuanced expressions such as sarcasm, irony, and mixed sentiments, which often require a level of language understanding that current models struggle to achieve. Although transformer-based models have advanced context understanding, they are not infallible when external knowledge or cultural context is necessary for accurate interpretation The limitation in cross-domain performance Ethical concerns, including biases in training data that can influence model output and reinforce harmful stereotypes References [1] Jähde, Orlando, Thorsten Weber, and Rüdiger Buchkremer. \u0026ldquo;Unraveling media perspectives: a comprehensive methodology combining large language models, topic modeling, sentiment analysis, and ontology learning to analyse media bias.\u0026rdquo; Journal of Computational Social Science 8, no. 2 (2025): 1-56.\n[2] van der Veen, A. Maurits, and Erik Bleich. \u0026ldquo;The advantages of lexicon-based sentiment analysis in an age of machine learning.\u0026rdquo; PloS one 20, no. 1 (2025): e0313092.\n[3] Alotaibi, Alanoud, Farrukh Nadeem, and Mohamed Hamdy. \u0026ldquo;Weakly Supervised Deep Learning for Arabic Tweet Sentiment Analysis on Education Reforms: Leveraging Pre-trained Models and LLMs with Snorkel.\u0026rdquo; IEEE Access (2025).\n[4] Rathje, Steve, Dan-Mircea Mirea, Ilia Sucholutsky, Raja Marjieh, Claire E. Robertson, and Jay J. Van Bavel. \u0026ldquo;GPT is an effective tool for multilingual psychological text analysis.\u0026rdquo; Proceedings of the National Academy of Sciences 121, no. 34 (2024): e2308950121.\n[5] Chatzimina, Maria Evangelia, Helen A. Papadaki, Charalampos Pontikoglou, and Manolis Tsiknakis. \u0026ldquo;A comparative sentiment analysis of Greek clinical conversations using BERT, RoBERTa, GPT-2, and XLNet.\u0026rdquo; Bioengineering 11, no. 6 (2024): 521.\n[6] Albladi, Aish, Minarul Islam, and Cheryl Seals. \u0026ldquo;Sentiment Analysis of Twitter data using NLP Models: A Comprehensive Review.\u0026rdquo; IEEE Access (2025).\n","permalink":"https://yningg.github.io/Blogs/posts/research/sentiment_analysis/","summary":"\u003cp\u003e(Left appox. 3 papers to be updated in recent days)\u003c/p\u003e\n\u003cp\u003eHere is a literature note on selected recent advancements in sentiment analysis techniques. The papers, published between 2024 and 2025 to date, all involve the application and/or discussion of LLMs in sentiment analysis tasks.\u003c/p\u003e\n\u003ch2 id=\"taxonomy-of-sentiment-analysis-techniques\"\u003eTaxonomy of Sentiment Analysis Techniques\u003c/h2\u003e\n\u003cp\u003eHere I combine the taxonomies adopted in [2] and [6] to involve all mentioned sentiment analysis techniques.\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eLexicon-based Methods\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003ePossible to measure gradations in sentiment\u003c/li\u003e\n\u003cli\u003eMore intrinsically suited to types of questions social scientists often ask, for example:\n\u003cul\u003e\n\u003cli\u003eTrends over time in average sentiment across large quantities of texts\u003c/li\u003e\n\u003cli\u003eWhether one group of texts is more negative than another\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eTraditional Machine Learning Models\u003c/strong\u003e (e.g., Naive Bayes, Support Vector Machines (SVM))\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDeep Learning Models\u003c/strong\u003e (e.g., Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs))\n\u003cul\u003e\n\u003cli\u003eCan learn hierarchical and sequential patterns in text, more suitable for sentiment analysis on informal social media platforms\u003c/li\u003e\n\u003cli\u003eAppealing for domain-specific applications\u003c/li\u003e\n\u003cli\u003ePerformance degrades rapidly when methods are applied to other domains\u003c/li\u003e\n\u003cli\u003eOften require large labeled datasets and computational resources\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eTransformer-based Architectures\u003c/strong\u003e (e.g., BERT, RoBERTa, and GPT)\n\u003cul\u003e\n\u003cli\u003eCan address challenges specific to Twitter, including brevity, mixed sentiments, and multilingual content\u003c/li\u003e\n\u003cli\u003eHave high computational cost and require domain-specific adaptation\u003c/li\u003e\n\u003cli\u003eHave built-in bias even without domain-specific fine-tuning. Even explicitly de-biased LLMs continue to reflect pernicious biases.\u003c/li\u003e\n\u003cli\u003eSupervised/Fine-tuned LLMs\n\u003cul\u003e\n\u003cli\u003ePros: require fewer labeled samples\u003c/li\u003e\n\u003cli\u003eCons:\n\u003cul\u003e\n\u003cli\u003eMay represent \u0026ldquo;catastrophic forgetting\u0026rdquo;, in which fine-tuning a general model for the sentiment analysis task risks losing many of the strengths of the pre-trained model\u003c/li\u003e\n\u003cli\u003eThere are often unexpected (and unnoticed) pitfalls in trying to keep the training, validation, and application steps of the machine learning model separate, which may invalidate findings\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eComparing to the supervised methods, unsupervised methods (i.e., Lexicon-based methods and unsupervised learning methods) are more domain-independent.\u003c/p\u003e","title":"Recent Advances on Sentiment Analysis"},{"content":" This paper is the first paper that propose the problem of community search. Keywords: $k$-core; Undirected graph; Size-constraints; Greedy algorithm; Heuristic Algorithms\n1 Motivations Discovering communities in graphs and social networks has drawn a large amount of attention in recent years. Most of the work has focused on the scenario where communities need to be discovered in an a priori manner, with only reference to the input graph. However, in many application scenarios, we are interested in discovering the community defined by a given set of nodes.\n1.1 Potential Applications Social-network analysis, collaborative tagging systems, query-log analysis, biology, and others.\n2 Problem Statements Problem 1 (Generic objective function): Given an undirected (connected) graph $G = (V, E)$, a set of query nodes $Q \\subseteq V$ , and a goodness function $f$, we seek to find an induced subgraph $H = (V_H, E_H )$ of $G$, such that:\n$V_H$ contains $Q$ ($Q \\subseteq V_H$); $H$ is connected; $f(H)$ is maximized among all feasible choices for $H$. Functions that capture the density of the subgraph $H$ are considered.\n$\\frac{|V_H| \\cdot (|V_H|-1)}{2}$: since even in its simplest form this density definition leads to NP-hard problems, so this definition is not considered. The average degree $f_a(H)$ of the nodes in $H$ ($\\frac{2|E_H|}{V_H}$). However, using this measure can lead to non intuitive results. The minimum degree $f_m(H)$ of the nodes in $H$ (Considered). Though it\u0026rsquo;s sensitive to outliers, it does not suffer from the problem of attaching a non-related community. Another way to avoid the pathological situations of attaching communities that are far way from query nodes, is to set a distance constraint:\nSet $d_G(v, q)$ as the length of the shortest path between nodes $v$ and $q$ in the graph $G$. If $v$ and $q$ are in different connected components, then $d_G(v, q) = \\infty$. The distance of $v$ from the query nodes $Q$: $D_Q(G, v) = \\sum_{q \\in Q} d_G(v, q)^2$ The distance of the furthest node from $Q$: $D_Q(G) = \\max_{v \\in V(G)}{D_Q(G, v)}$ Problem 2 (Concrete Problem): Given an undirected (connected) graph $G = (V, E)$, a set of query nodes $Q \\subseteq V$, and a number $d$ to be interpreted as a distance constraint, we seek to find an induced subgraph $H = (V_H, E_H)$ of $G$, such that:\n$V_H$ contains $Q (Q \\subseteq V_H)$; $H$ is connected; $D_Q(H) \\leq d$; The minimum degree function $f_m(H)$ is maximized among all feasible choices for $H$. 3 Community Search Algorithms 3.1 Communities Without Size Constraints The GREEDY algorithm was proposed and studied by Asahiro et al. and later analyzed by Charikar, who showed that it achieves a factor 2 approximation guarantee for the densest-subgraph problem.\n*A factor 2 approximation means: The solution the algorithm gives you is guaranteed to be at least half as good as the best possible solution.\n3.1.1 GREEDY algorithm Let $G_0 = G$ For each t-th step of execution, Delete a node $u$ that has minimum degree in $G_{t−1}$ and all the edges incident to $u$ from $G_{t-1}$ to obtain graph $G_t$ Extract the connected component of $G_t$, $G_t^{\u0026rsquo;}$, which contains all query nodes $Q$ Compute $f_m(G_t^{\u0026rsquo;})$ and compare with the previous step Stop at the step if either (i) at least one of the query nodes $Q$ has minimum degree in the graph $G_{T −1}$, or (ii) the query nodes $Q$ are no longer connected. Returns the solution $G_O$ for $G_t^{\u0026rsquo;}$ where $f_m(G_t^{\u0026rsquo;})$ is maximized ($G_O = arg max {f_m(G_t^{\u0026rsquo;})| t=1,\u0026hellip;,T-1}$). Greedy can be implemented in linear time and can be used to find an optimal solution for any monotone function.\nDrawback of GREEDY: it may return subgraphs of very large size.\n3.1.2 Generalization to monotone functions The algorithm GREEDY can be used to find an optimal solution for any monotone function.\nDefinition 1 (Monotone function) The function $f$ is monotone non-increasing if for every graph $G$ and for every induced subgraph $H$ of $G$,$f(H) \\leq f(G)$. We similarly define $f$ to be monotone non-decreasing by requiring $f(H) \\geq f(G)$.\nDefinition 2 (Node-monotone function) A function $f$ is said to be node-monotone non-increasing if for every graph $G$, for every induced subgraph $H$ of $G$, and every node $v$ in $H$, $f(H, v) \\leq f(G, v)$. We similarly define node-monotone non-decreasing functions.\nThe degree function $d(G, v)$, minimum degree function $f_m(G)$ and distance functions $D_Q(G, v)$ and $D_Q(G)$ are all monotone.\nThe generalization of the community-search problem.\nProblem 3 (Cocktail party) We are given an undirected graph $G = (V, E)$, a node-monotone non-increasing function $f: G_V × V \\rightarrow \\mathbb{R}$, as well as a set of monotone non-increasing properties $f_1, \u0026hellip;, f_k$. We seek to find an induced subgraph $H$ of $G$ that maximizes $f$ among all induced subgraphs of $G$, and satisfies $f_1, \u0026hellip;, f_k$. A similar problem can be defined by considering to minimize monotone non-decreasing functions.\nFor solving the Problem 3, we generalize the algorithm GREEDY to GREEDYGEN. In detail, the GREEDYGEN algorithm is described as follows:\nStart from $G_0 = G$ For each step: While $G_t$ is not empty: Check if $G_t$ satisfies all properties Return the subgraph which maximizes $f$ among all graphs $G_t$ that are constructed throughout the execution of the algorithm and satisfy all the monotone properties Check whether there is a property $f_j$ and a node $v \\in V$ such that $v$ violates $f_j$, $j = 1, \u0026hellip;, k$. If find such a node, delete $v$ and all the incident edges of $v$ Otherwise, delete from $G$ a node $v$ such that $f(G, v)$ is minimum. The algorithm GreedyGen always returns an optimum solution for Problem 3. The exact running time of the algorithm depends on the constraints employed.\n3.2 Communities With Size Constraints If there is a specified upper bound of the size of output subgraph, the community search problem becomes NP-hard. Therefore, two simple yet effective heuristics algorithms are proposed.\nProblem 4 (Minimum degree with upper bound on the size): Given an undirected (connected) graph $G = (V_G, E_G)$, a set of query nodes $Q \\subseteq V$ , a number $d$ (distance constraint), and an integer $k$ (size constraint), we wish to find an induced subgraph $H = (V_H, E_H)$ of $G$, such that:\n$H$ contains the query nodes ($Q \\subseteq H$); $H$ is connected; $D_Q(H) \\leq d$; $|V_H| \\leq k$ ($H$ has at most $k$ nodes); The minimum degree of $H$ is maximized. The proof of NP-hardness of this problem is using the reduction to the Steiner-tree problem with unit weights.\nThe two heuristics provide a quality–efficiency trade-off: GreedyDist tries to optimize quality while GreedyFast tries to optimize efficiency.\nFirst Heuristic Algorithm: GREEDYDIST($G$, $Q$, $k$, $d$) The design principle is the simple observation that a tighter distance constraint implies smaller communities (d $\\downarrow$, size $\\downarrow$). GREEDYDIST uses the algorithm GREEDYGEN as a subroutine.\nExecute the algorithm GREEDYGEN in order to maximize the minimum degree subject to the distance constraint $d$ that is specified in input. If the query nodes are connected and the size constraint is not satisfied in the output graph, then execute GREEDYGEN again with a tighter distance bound $d\u0026rsquo; \u0026lt; d$ (d\u0026ndash;). GREEDYDIST iterates executing GREEDYGEN by decreasing at each step the distance constraint, until: The size constraint is satisfied, or The query nodes become disconnected. In this case, GREEDYDIST returns the smallest graph found among all executions of GREEDYGEN that is connected. Second Heuristic Algorithm: GREEDYFAST($G$, $Q$, $k$, $d$) There is a preprocessing phase where the input graph is restricted to the $k\u0026rsquo;$ closest nodes to the query nodes. The distance of a node to the query nodes is measured using the function $D_Q$ defined in Equation (1).\nAfter this preprocessing phase, we execute GREEDY on the restricted graph formed in the preprocessing phase. The intuition for doing this is that the closer a node is to the query nodes, the more likely it belongs to the community.\nExperimental Evaluation Datasets: DBLP, tag, BIOMINE\nEfficiency metrics: running time\nEffectiveness metrics: the minimum degree $f_m$, the average degree (density) $f_a$, size and distance.\nSensitivity analysis:\nNumber of query nodes Distance between query nodes Upper bound on the number of nodes Case study: show the quality of the algorithm results\n","permalink":"https://yningg.github.io/Blogs/posts/research/sozio2010community/","summary":"\u003cblockquote\u003e\n\u003cp\u003eThis paper is the \u003cstrong\u003efirst\u003c/strong\u003e paper that propose the problem of community search.\nKeywords: $k$-core; Undirected graph; Size-constraints; Greedy algorithm; Heuristic Algorithms\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2 id=\"1-motivations\"\u003e1 Motivations\u003c/h2\u003e\n\u003cp\u003eDiscovering communities in graphs and social networks has drawn a large amount of attention in recent years. Most of the work has focused on the scenario where communities need to be discovered in an a priori manner, with only reference to the input graph. \u003cu\u003eHowever, in many application scenarios, we are interested in discovering the community defined by a given set of nodes.\u003c/u\u003e\u003c/p\u003e","title":"The community-search problem and how to plan a successful cocktail party"},{"content":"阅读时间：2023-03-03 \u0026ndash;\u0026gt; 2023-04-11\n实用建议与方法 解决负债问题的四个忠告 停用信用卡； 应该尽可能少地偿还贷款，也就是分期付款（尽量多分几期）。分期付款额越高，每个月剩下的生活费就越少； 针对消费贷款（与住房无关的贷款）：将不用于生活的那部分钱的一半存起来，一半用于偿还贷款； a. 需要注意的一种心态是，“债务应当尽快还清”。如果把所有不用于生活的钱都用来还债，虽然会感觉肩上的一个重担就可以卸下来， 但当还清了债务的时候，也一无所有了。一无所有并不是财务管理的目标。 b. 所有的消费贷款都是不明智的。聪明的做法是只把以前积攒起来的财富用于支出。 在每次支付一笔账单时，都反问自己是否真的需要购买这个东西。 收入的分配 50%的钱用作投资,用40%的钱用来实现中短期目标,用10%的钱用来零花（应该以实际财务状况和开销来决定）。\n投资需要注意的三点 应该把钱投资在安全的地方； 我的钱应该可以产生丰厚的利息，所以就应该看一看，哪种投资的利息最高。而最高的红利总共是从股票上获得的，这一点你们需要知道； 我们的投资应该简洁明了而且易于操作。 关于基金 基金就像一口大锅，许多没有时间、没有相关知识或者没有情绪亲自去买股票的投资人会把钱投进这口锅里，这些钱由基金经理人去投资买股票。 当遇到股票行情下跌的时候，不要卖出。在这种时候，只有当你把股票实际卖出的时候，才会有损失。\n挑选基金时的注意事项：\n基金应该至少有10年历史。假如它在这么长时间内一直有丰厚的利润，那我们可以认为，未来 它也会运作良好。 应该选择大型的跨国股票基金。这种基金在世界各地购买股票，以此分散风险，所以十分安全。 对基金的走势图进行比较。我们应该观察在过去10年间哪些基金的年终利润最好。 风险分散：日拆 处于分散风险的考虑，应该把一部分钱投资在绝对安全的地方。银行还提供了很多更好的选择，比如你可以投资日拆，这是一种银行向证券公司提供的短期贷款，当天结算。\n这种投资的收入是根据市场行情变化的，这笔钱你随时可以动用。 日拆虽然利率不高，但总不能把你所有的钱都投资买股票，该留一些现金做储备。只有这样才能达到分散风险的最佳效果 投资20%的钱到日拆就够了 关于理财的心态 你是否能挣到钱，最关键的并不是你有没有好点子，也不是你有多聪明，而是你的自信程度。你的自信程度决定了你是否相信自己的能力，是否相信你自己。假如你根本不相信你能做到的话，那么你根本不会动手去做，而假如你不开始去做，那么你就什么也得不到。把精力集中在知道、能做和拥有的东西上。\n“困难总是在不断地出现。尽管如此，你每天还是要去不间断地做对你的未来意义重大的事情。你为此花费的时间不会超过10分钟，但是就是这10分钟会让一切变得不同。大多数人总是在现有的水平上停滞不前，就是因为他们没有拿出这10分钟。他们总是期望情况能向有利于自己的方向转变，但是他们忽视了一点，那就是他们首先必须改变自己。”\n原文摘录 大部分人并不清楚自己想要的是什么，他们只知道，自己想得到更多的东西。我们必须确切地知道自己心里渴望的是什么才行。\n太多的人做事犹豫不决，就是因为他们觉得没有完全弄懂这件事。真正付诸实践要比纯粹的思考有用多了。\n“我会试试看。” “不是试试看，而是去切实行动！如果你只是抱着试试看的心态，那么你只会以失败告终，你会一事无成。‘尝试’纯粹是一种借口，你还没有做，就已经给自己想好了退路。不能试验，你只有两个选择——做或者不做。”\n如果你不去做某件事的原因不是出于自己的意愿，而是别人要你这么做，那么你就已经失去了自己的权利。当你把责任推脱给别人的同时，也把权利转让给了他。\n勇敢的人也会害怕，一个人虽然害怕却依然敢于前进，这才叫勇敢。\n“要想过更幸福、更满意的生活，人就得改变自身。这和钱无关，金钱本身既不会使人幸福，也不会带来不幸。金钱是中性的，既不好，也不坏。只有当钱属于某一个人的时候，他才会对这个人产生好的影响或者坏的影响。钱可以被用于好的用途，也可以被用于坏的用途。一个幸福的人有了钱会更幸福；而一个悲观忧虑的人，钱越多，烦恼就越多。”\n“金钱会暴露一个人的本性，金钱就像一个放大镜，它帮你更充分地展现出你本来的样子。好人可以用钱做很多好事。而如果你是盗贼，那你很可能会把钱挥霍在一些蠢事上。”\n“金钱能成为我们生活中非常强大的助推力。金钱可以在一定程度上提高我们的生活水平——生活的许多方面都是以钱为基础的。有了钱，我们就更容易实现我们的目标和梦想——当然，包括好的目标和梦想，也包括坏的目标和梦想。”\n回到朋友们中间吼，赞扬的话语纷纷朝我涌来。妈妈自豪地挽着我的胳膊，爸爸抚摸着我的头发。最初的喧嚣平息后，金先生用一种恳切的语调对我说：“我真为你骄傲。”\n我羞涩地否认说：“我刚才很紧张，把一堆我想说的话都忘掉了。”\n金先生坚持自己的说法：“你应该直截了当地接受我的称赞，因为我刚刚对你讲的这句话，我并不经常说出口，我真的为你骄傲。你很有演讲天赋，大家喜欢听你说话。其实大家根本不知道你本来还准备讲些什么。”\n他停顿了片刻，接着又说：“如果你没有做今天这件事情，你就永远不会知道，给自己一些压力之后，你能够做到些什么。一个人觉得最引以为自豪的事情，往往是那些做起来最艰难的事情。这一点你千万不要忘记。”\n不要为失去的东西而忧伤，而要对拥有它的时光心存感激。\n中欧地区对“童年”这个概念的理解包括“废除剥削儿童的童工劳动，维护儿童的权益”等内容。它源于良好的愿望，但也有消极的一面，造成了儿童与社会的日益隔绝与童年期的延长，以及对孩子们过分保护和幼稚化的倾向。想要找出一个适合我们这个矛盾时代的对“童年”的解释，重要的是不要继续把孩子们培养成温驯听话的小绵羊，不要再用喂他们镇定剂的方式对他们进行职业素质教育。\n孩子们具有掌握自己发展方向的潜力。因此，成年人不要替孩子们决定该如何发展，而是应该理解、支持他们，帮助他们成长，要相信孩子们的自觉性和进取心。\n我们应该要求孩子们具有小心谨慎和不屈不挠的品质，并有意识在这些方面培养他们。因此，在遇到需要解决的问题时，不要直接把答案摊在他们面前，而是应该给他们机会，让他们自己去寻找解决办法，使他们通过扩大视角、深入调查来体验研究、发现和实验的学习过程。\n你与其把注意力只集中在损失上，倒不如为能拥有它这么长时间而感到高兴。“精明的老妇人回答道，”一旦我们坐船到达对岸，也就不再需要那只船了。”\n吉娅对此有不同的意见，她问：“要是我还想回去，也就是说回到我先前出发的岸边去，又该怎么办呢？”\n老妇人意味深长地说：“这在生活中是不可能的。生活始终向前行进。你可以暂时休息一下或者安静地聚集新的能量，但你永远也无法再回去了。\n“有时候我也希望自己能再年轻几岁，那样一切就更简单了。”吉娅自言自语道。\n老妇人点头表示同意，她说：“我相信成年人有时也会有这样的想法，但生活本身是一次旅行，总是一直向前。我们中的大多数人总是先到外面去建造甜甜圈那外在的一圈：上学、找工作、买房子、买汽车、储蓄及投资。但在这之后，有些人的旅行就会在某个时刻开始转入内在，他们会关注起自己的品格。而那正是所谓的甜甜圈的圆孔。人们不断地前往新的“河岸”、开启新的冒险，而一些明智的人再此过程中能同时注重物质和品格两个方面。”\n","permalink":"https://yningg.github.io/Blogs/posts/books/puppymoney/","summary":"\u003cp\u003e阅读时间：2023-03-03 \u0026ndash;\u0026gt; 2023-04-11\u003c/p\u003e\n\u003ch2 id=\"实用建议与方法\"\u003e实用建议与方法\u003c/h2\u003e\n\u003ch3 id=\"解决负债问题的四个忠告\"\u003e解决负债问题的四个忠告\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e停用信用卡；\u003c/li\u003e\n\u003cli\u003e应该尽可能少地偿还贷款，也就是分期付款（尽量多分几期）。分期付款额越高，每个月剩下的生活费就越少；\u003c/li\u003e\n\u003cli\u003e针对消费贷款（与住房无关的贷款）：将不用于生活的那部分钱的一半存起来，一半用于偿还贷款；\na. \u003cem\u003e需要注意的一种心态是，“债务应当尽快还清”。如果把所有不用于生活的钱都用来还债，虽然会感觉肩上的一个重担就可以卸下来， 但当还清了债务的时候，也一无所有了。一无所有并不是财务管理的目标。\u003c/em\u003e\nb. 所有的消费贷款都是不明智的。聪明的做法是只把以前积攒起来的财富用于支出。\u003c/li\u003e\n\u003cli\u003e在每次支付一笔账单时，都反问自己是否真的需要购买这个东西。\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"收入的分配\"\u003e收入的分配\u003c/h3\u003e\n\u003cp\u003e50%的钱用作投资,用40%的钱用来实现中短期目标,用10%的钱用来零花（应该以实际财务状况和开销来决定）。\u003c/p\u003e\n\u003ch3 id=\"投资需要注意的三点\"\u003e投资需要注意的三点\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e应该把钱投资在安全的地方；\u003c/li\u003e\n\u003cli\u003e我的钱应该可以产生丰厚的利息，所以就应该看一看，哪种投资的利息最高。而最高的红利总共是从股票上获得的，这一点你们需要知道；\u003c/li\u003e\n\u003cli\u003e我们的投资应该简洁明了而且易于操作。\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"关于基金\"\u003e关于基金\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003e基金就像一口大锅，许多没有时间、没有相关知识或者没有情绪亲自去买股票的投资人会把钱投进这口锅里，这些钱由基金经理人去投资买股票。\n\u003cem\u003e当遇到股票行情下跌的时候，不要卖出。在这种时候，只有当你把股票实际卖出的时候，才会有损失。\u003c/em\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003cstrong\u003e挑选基金时的注意事项\u003c/strong\u003e：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e基金应该至少有10年历史。假如它在这么长时间内一直有丰厚的利润，那我们可以认为，未来 它也会运作良好。\u003c/li\u003e\n\u003cli\u003e应该选择大型的跨国股票基金。这种基金在世界各地购买股票，以此分散风险，所以十分安全。\u003c/li\u003e\n\u003cli\u003e对基金的走势图进行比较。我们应该观察在过去10年间哪些基金的年终利润最好。\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"风险分散日拆\"\u003e风险分散：日拆\u003c/h3\u003e\n\u003cp\u003e处于分散风险的考虑，应该把一部分钱投资在绝对安全的地方。银行还提供了很多更好的选择，比如你可以投资日拆，这是一种银行向证券公司提供的短期贷款，当天结算。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e这种投资的收入是根据市场行情变化的，这笔钱你随时可以动用。\u003c/li\u003e\n\u003cli\u003e日拆虽然利率不高，但总不能把你所有的钱都投资买股票，该留一些现金做储备。只有这样才能达到分散风险的最佳效果\u003c/li\u003e\n\u003cli\u003e投资20%的钱到日拆就够了\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"关于理财的心态\"\u003e关于理财的心态\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e你是否能挣到钱，最关键的并不是你有没有好点子，也不是你有多聪明，而是你的自信程度。你的自信程度决定了你是否相信自己的能力，是否相信你自己。假如你根本不相信你能做到的话，那么你根本不会动手去做，而假如你不开始去做，那么你就什么也得不到。\u003cstrong\u003e把精力集中在知道、能做和拥有的东西上\u003c/strong\u003e。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e“困难总是在不断地出现。尽管如此，你每天还是要去不间断地做对你的未来意义重大的事情。你为此花费的时间不会超过10分钟，但是就是这10分钟会让一切变得不同。大多数人总是在现有的水平上停滞不前，就是因为他们没有拿出这10分钟。他们总是期望情况能向有利于自己的方向转变，但是他们忽视了一点，那就是他们首先必须改变自己。”\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"原文摘录\"\u003e原文摘录\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e大部分人并不清楚自己想要的是什么，他们只知道，自己想得到更多的东西。我们必须确切地知道自己心里渴望的是什么才行。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cblockquote\u003e\n\u003cp\u003e太多的人做事犹豫不决，就是因为他们觉得没有完全弄懂这件事。\u003cstrong\u003e真正付诸实践要比纯粹的思考有用多了\u003c/strong\u003e。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cblockquote\u003e\n\u003cp\u003e“我会试试看。”\n“\u003cstrong\u003e不是试试看，而是去切实行动\u003c/strong\u003e！如果你只是抱着试试看的心态，那么你只会以失败告终，你会一事无成。‘尝试’纯粹是一种借口，你还没有做，就已经给自己想好了退路。不能试验，你只有两个选择——做或者不做。”\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cblockquote\u003e\n\u003cp\u003e如果你不去做某件事的原因不是出于自己的意愿，而是别人要你这么做，那么你就已经失去了自己的权利。当你把责任推脱给别人的同时，也把权利转让给了他。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cblockquote\u003e\n\u003cp\u003e勇敢的人也会害怕，一个人虽然害怕却依然敢于前进，这才叫勇敢。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cblockquote\u003e\n\u003cp\u003e“要想过更幸福、更满意的生活，人就得改变自身。这和钱无关，金钱本身既不会使人幸福，也不会带来不幸。\u003cstrong\u003e金钱是中性的，既不好，也不坏。只有当钱属于某一个人的时候，他才会对这个人产生好的影响或者坏的影响\u003c/strong\u003e。钱可以被用于好的用途，也可以被用于坏的用途。一个幸福的人有了钱会更幸福；而一个悲观忧虑的人，钱越多，烦恼就越多。”\u003c/p\u003e\n\u003cp\u003e“金钱会暴露一个人的本性，金钱就像一个放大镜，它帮你更充分地展现出你本来的样子。好人可以用钱做很多好事。而如果你是盗贼，那你很可能会把钱挥霍在一些蠢事上。”\u003c/p\u003e\n\u003cp\u003e“金钱能成为我们生活中非常强大的助推力。金钱可以在一定程度上提高我们的生活水平——生活的许多方面都是以钱为基础的。有了钱，我们就更容易实现我们的目标和梦想——当然，包括好的目标和梦想，也包括坏的目标和梦想。”\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cblockquote\u003e\n\u003cp\u003e回到朋友们中间吼，赞扬的话语纷纷朝我涌来。妈妈自豪地挽着我的胳膊，爸爸抚摸着我的头发。最初的喧嚣平息后，金先生用一种恳切的语调对我说：“我真为你骄傲。”\u003c/p\u003e\n\u003cp\u003e我羞涩地否认说：“我刚才很紧张，把一堆我想说的话都忘掉了。”\u003c/p\u003e\n\u003cp\u003e金先生坚持自己的说法：“你应该直截了当地接受我的称赞，因为我刚刚对你讲的这句话，我并不经常说出口，我真的为你骄傲。你很有演讲天赋，大家喜欢听你说话。其实大家根本不知道你本来还准备讲些什么。”\u003c/p\u003e\n\u003cp\u003e他停顿了片刻，接着又说：“如果你没有做今天这件事情，你就永远不会知道，给自己一些压力之后，你能够做到些什么。\u003cstrong\u003e一个人觉得最引以为自豪的事情，往往是那些做起来最艰难的事情。这一点你千万不要忘记\u003c/strong\u003e。”\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cblockquote\u003e\n\u003cp\u003e不要为失去的东西而忧伤，而要对拥有它的时光心存感激。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cblockquote\u003e\n\u003cp\u003e中欧地区对“童年”这个概念的理解包括“废除剥削儿童的童工劳动，维护儿童的权益”等内容。它源于良好的愿望，但也有消极的一面，造成了儿童与社会的日益隔绝与童年期的延长，以及对孩子们过分保护和幼稚化的倾向。想要找出一个适合我们这个矛盾时代的对“童年”的解释，重要的是不要继续把孩子们培养成温驯听话的小绵羊，不要再用喂他们镇定剂的方式对他们进行职业素质教育。\u003c/p\u003e\n\u003cp\u003e孩子们具有掌握自己发展方向的潜力。因此，成年人不要替孩子们决定该如何发展，而是应该理解、支持他们，帮助他们成长，要相信孩子们的自觉性和进取心。\u003c/p\u003e\n\u003cp\u003e我们应该要求孩子们具有小心谨慎和不屈不挠的品质，并有意识在这些方面培养他们。因此，在遇到需要解决的问题时，不要直接把答案摊在他们面前，而是应该给他们机会，让他们自己去寻找解决办法，使他们通过扩大视角、深入调查来体验研究、发现和实验的学习过程。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e你与其把注意力只集中在损失上，倒不如为能拥有它这么长时间而感到高兴\u003c/strong\u003e。“精明的老妇人回答道，”一旦我们坐船到达对岸，也就不再需要那只船了。”\u003c/p\u003e\n\u003cp\u003e吉娅对此有不同的意见，她问：“要是我还想回去，也就是说回到我先前出发的岸边去，又该怎么办呢？”\u003c/p\u003e\n\u003cp\u003e老妇人意味深长地说：“这在生活中是不可能的。生活始终向前行进。你可以暂时休息一下或者安静地聚集新的能量，但你永远也无法再回去了。\u003c/p\u003e\n\u003cp\u003e“有时候我也希望自己能再年轻几岁，那样一切就更简单了。”吉娅自言自语道。\u003c/p\u003e\n\u003cp\u003e老妇人点头表示同意，她说：“我相信成年人有时也会有这样的想法，但生活本身是一次旅行，总是一直向前。我们中的大多数人总是先到外面去建造甜甜圈那外在的一圈：上学、找工作、买房子、买汽车、储蓄及投资。但在这之后，有些人的旅行就会在某个时刻开始转入内在，他们会关注起自己的品格。而那正是所谓的甜甜圈的圆孔。人们不断地前往新的“河岸”、开启新的冒险，而一些明智的人再此过程中能同时注重物质和品格两个方面。”\u003c/p\u003e\n\u003c/blockquote\u003e","title":"Reading Notes: 《小狗钱钱》"},{"content":"Preparation Phase PowerPoint Basics Font Using Sans Serif fonts instead of Serif fonts makes it easier for the audience to read the text quickly. Examples of Sans Serif fonts include Arial, Comic Sans, and Trebuchet Type size should be within the range of 18 point to 36 point, except adding references at the bottom Avoid using all capital letters Color The color combination between letters and background should be high contrast A dark blue or black background works best for talks in a large room Dark letters against a light background are best for small rooms or teaching There is no need for a university logo to be on each slide Layout Every slide should have a heading, a simple but purposeful sentence. For more effective headers, consider: Using questions as headers to simulate a \u0026ldquo;conversation\u0026rdquo; Using the assertion-evidence structure Limit text blocks to no more than two lines each Lists should contain no more than 3 items, and \u0026ldquo;unveil\u0026rdquo; the list one by one Be generous with empty space, especially at the top and the bottom Style Include a simple image on every slide Limit the number of items on each slide; each slide should make just one or two points, and explain the points completely If you\u0026rsquo;re not going to take the time to explain it, get rid of it Avoid fancy transitions between slides unless you have a good reason Don\u0026rsquo;t drown the audience with data, less is more Three Functions of Slides Visual repetition of key points: to draw attention to \u0026amp; reinforce key messages Complement spoken text: additional info not said Replace Speaker (temporarily): e.g., a video, show whole paragraph or table \u0026amp; ask audience to read while keeping silent The structure of slides: start broad, get specific, end broad Start with the biggest questions and get progressively more specific In the middle of the talk, go into depth, but use the home slide to make transitions (enable the audience to tune back in) To conclude, reiterate the main conclusions and go back to the big picture During Q\u0026amp;A, put the summary slide back up again Review Each Slide Make sure each slide serves its PURPOSE Each slide has MAIN POINTS thatthe audience must see within 5 seconds Check whether the slide will make the audience LISTEN or spend some time looking at the slide During Presentation Useful Slide Transition Wordings \u0026ldquo;Now, what are \u0026hellip;?\u0026rdquo; (use of questions) \u0026ldquo;My next point is \u0026hellip;\u0026rdquo; \u0026ldquo;Now that I\u0026rsquo;ve finished talking about \u0026hellip;, let\u0026rsquo;s move on to \u0026hellip;\u0026rdquo; \u0026ldquo;You\u0026rsquo;ve just seen \u0026hellip;, so we\u0026rsquo;ll now turn out attention to my second point: \u0026hellip;\u0026rdquo; \u0026ldquo;In addition to the factors we have discussed, I want to add \u0026hellip;\u0026rdquo; Remind Vocal Dynamics Change pace to emphasize key points Change pitch to create interest Change volume to emphasize contrast Punc-tu-ate syllables and words for emphasis Pause before important information to provide anticipation Avoid Vocal Distracters Vocalized pauses (um.., er.., ah..) Filler words (ok, you know, actually) Breathlessness Voice dropping or rising at the end of a sentence Mumbling /slurring Q\u0026amp;A Session Different types of questions:\nClarification questions: dealing with points mentioned in the presentation Application/Significance questions: relating to the value of research Problem questions: regarding perceived problems with research; Miscellaneous questions: concerning minor issues related to research Handling Questions When don\u0026rsquo;t know the answer:\nSimply say \u0026ldquo;I don\u0026rsquo;t know, but\u0026hellip;\u0026rdquo;, to say what you would do the get the information to the asker Or if you have the hunch, still say, \u0026ldquo;I don\u0026rsquo;t know, but I will follow up with you as soon as I can.\u0026rdquo; Then, follow with your hunch: \u0026ldquo;But my hunch is, the answer may sound like this\u0026hellip;\u0026rdquo; When the multiple questions are asked one after another (Machine gun questions):\nPick one or two that you still remember and answer them Ask the asker to repeat the question May not be a question but a statement:\nWhen the people take a breath, start to paraphrase what has been said and ask a question for him/her: \u0026ldquo;So what you are saying is \u0026hellip; \u0026quot; When someone asks a question with loaded emotions:\nIt\u0026rsquo;s best to acknowledge the emotion in a generic term: \u0026ldquo;It sounds like you have a lot of passion on this topic\u0026hellip;\u0026rdquo; and go ahead and paraphrase the question Referenced Sources Susan McConnell (Stanford): Designing effective scientific presentations: https://www.youtube.com/watch?v=Hp7Id3Yb9XQ Handing Difficult Questions During a Presentation: https://www.youtube.com/watch?app=desktop\u0026amp;v=__wN6LdGSto Research Communication Tutorials Held by Dr.Ritu Jain ","permalink":"https://yningg.github.io/Blogs/posts/research/oral_presentation/","summary":"\u003ch2 id=\"preparation-phase\"\u003ePreparation Phase\u003c/h2\u003e\n\u003ch3 id=\"powerpoint-basics\"\u003ePowerPoint Basics\u003c/h3\u003e\n\u003ch4 id=\"font\"\u003eFont\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003eUsing \u003cstrong\u003eSans Serif\u003c/strong\u003e fonts instead of \u003cstrong\u003eSerif\u003c/strong\u003e fonts makes it easier for the audience to read the text quickly. Examples of Sans Serif fonts include \u003cem\u003eArial\u003c/em\u003e, \u003cem\u003eComic Sans\u003c/em\u003e, and \u003cem\u003eTrebuchet\u003c/em\u003e\u003c/li\u003e\n\u003cli\u003eType size should be within the range of 18 point to 36 point, except adding references at the bottom\u003c/li\u003e\n\u003cli\u003eAvoid using all capital letters\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"color\"\u003eColor\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003eThe color combination between letters and background should be \u003cstrong\u003ehigh contrast\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eA dark blue or black background works best for talks in a large room\u003c/li\u003e\n\u003cli\u003eDark letters against a light background are best for small rooms or teaching\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eThere is no need for a university logo to be on each slide\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"layout\"\u003eLayout\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003eEvery slide should have a heading, a \u003cstrong\u003esimple but purposeful\u003c/strong\u003e sentence. For more effective headers, consider:\n\u003cul\u003e\n\u003cli\u003eUsing questions as headers to simulate a \u0026ldquo;conversation\u0026rdquo;\u003c/li\u003e\n\u003cli\u003eUsing the assertion-evidence structure\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eLimit text blocks to no more than \u003cstrong\u003etwo\u003c/strong\u003e lines each\u003c/li\u003e\n\u003cli\u003eLists should contain no more than \u003cstrong\u003e3\u003c/strong\u003e items, and \u0026ldquo;unveil\u0026rdquo; the list one by one\u003c/li\u003e\n\u003cli\u003eBe generous with empty space, especially at the top and the bottom\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"style\"\u003eStyle\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003eInclude a simple image on every slide\u003c/li\u003e\n\u003cli\u003eLimit the number of items on each slide; each slide should make just one or two points, and explain the points completely\n\u003cul\u003e\n\u003cli\u003eIf you\u0026rsquo;re not going to take the time to explain it, get rid of it\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eAvoid fancy transitions between slides unless you have a good reason\u003c/li\u003e\n\u003cli\u003eDon\u0026rsquo;t drown the audience with data, less is more\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"three-functions-of-slides\"\u003eThree Functions of Slides\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eVisual repetition\u003c/strong\u003e of key points: to draw attention to \u0026amp; reinforce key messages\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eComplement\u003c/strong\u003e spoken text: additional info not said\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eReplace Speaker\u003c/strong\u003e (temporarily): e.g., a video, show whole paragraph or table \u0026amp; ask audience to read while keeping silent\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"the-structure-of-slides-start-broad-get-specific-end-broad\"\u003eThe structure of slides: start broad, get specific, end broad\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eStart with the biggest questions and get progressively more specific\u003c/li\u003e\n\u003cli\u003eIn the middle of the talk, go into depth, but use the home slide to make transitions (enable the audience to tune back in)\u003c/li\u003e\n\u003cli\u003eTo conclude, reiterate the main conclusions and go back to the big picture\u003c/li\u003e\n\u003cli\u003eDuring Q\u0026amp;A, put the summary slide back up again\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"review-each-slide\"\u003eReview Each Slide\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eMake sure each slide serves its PURPOSE\u003c/li\u003e\n\u003cli\u003eEach slide has MAIN POINTS thatthe  audience must see within 5 seconds\u003c/li\u003e\n\u003cli\u003eCheck whether the slide will make the audience LISTEN or spend some time looking at the slide\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"during-presentation\"\u003eDuring Presentation\u003c/h2\u003e\n\u003ch3 id=\"useful-slide-transition-wordings\"\u003eUseful Slide Transition Wordings\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u0026ldquo;Now, what are \u0026hellip;?\u0026rdquo; (use of questions)\u003c/li\u003e\n\u003cli\u003e\u0026ldquo;My next point is \u0026hellip;\u0026rdquo;\u003c/li\u003e\n\u003cli\u003e\u0026ldquo;Now that I\u0026rsquo;ve finished talking about \u0026hellip;, let\u0026rsquo;s move on to \u0026hellip;\u0026rdquo;\u003c/li\u003e\n\u003cli\u003e\u0026ldquo;You\u0026rsquo;ve just seen \u0026hellip;, so we\u0026rsquo;ll now turn out attention to my second point: \u0026hellip;\u0026rdquo;\u003c/li\u003e\n\u003cli\u003e\u0026ldquo;In addition to the factors we have discussed, I want to add \u0026hellip;\u0026rdquo;\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"remind-vocal-dynamics\"\u003eRemind Vocal Dynamics\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eChange \u003cstrong\u003epace\u003c/strong\u003e to emphasize key points\u003c/li\u003e\n\u003cli\u003eChange \u003cstrong\u003epitch\u003c/strong\u003e to create interest\u003c/li\u003e\n\u003cli\u003eChange \u003cstrong\u003evolume\u003c/strong\u003e to emphasize contrast\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePunc-tu-ate\u003c/strong\u003e syllables and words for emphasis\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePause\u003c/strong\u003e before important information to provide anticipation\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"avoid-vocal-distracters\"\u003eAvoid Vocal Distracters\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eVocalized pauses (um.., er.., ah..)\u003c/li\u003e\n\u003cli\u003eFiller words (ok, you know, actually)\u003c/li\u003e\n\u003cli\u003eBreathlessness\u003c/li\u003e\n\u003cli\u003eVoice dropping or rising at the end of a sentence\u003c/li\u003e\n\u003cli\u003eMumbling /slurring\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"qa-session\"\u003eQ\u0026amp;A Session\u003c/h2\u003e\n\u003cp\u003eDifferent types of questions:\u003c/p\u003e","title":"Notes for Preparing an Oral Presentation"},{"content":"Table for Community Search Papers Year Venue Title Graph Type Method Type Key Techniques Codebase 2023 PVLDB CommunityAF: An Example-Based Community Search Method via Autoregressive Flow Undirected graph Learning-based CommunityAF Framework https://github.com/JiazunChen/CommunityAF Reported Applications Recommendation; Personal background discovery; Anomaly detection;\n","permalink":"https://yningg.github.io/Blogs/posts/community_search_paper/","summary":"\u003ch1 id=\"table-for-community-search-papers\"\u003eTable for Community Search Papers\u003c/h1\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eYear\u003c/th\u003e\n          \u003cth\u003eVenue\u003c/th\u003e\n          \u003cth\u003eTitle\u003c/th\u003e\n          \u003cth\u003eGraph Type\u003c/th\u003e\n          \u003cth\u003eMethod Type\u003c/th\u003e\n          \u003cth\u003eKey Techniques\u003c/th\u003e\n          \u003cth\u003eCodebase\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2023\u003c/td\u003e\n          \u003ctd\u003ePVLDB\u003c/td\u003e\n          \u003ctd\u003eCommunityAF: An Example-Based Community Search Method via Autoregressive Flow\u003c/td\u003e\n          \u003ctd\u003eUndirected graph\u003c/td\u003e\n          \u003ctd\u003eLearning-based\u003c/td\u003e\n          \u003ctd\u003eCommunityAF Framework\u003c/td\u003e\n          \u003ctd\u003e\u003ca href=\"https://github.com/JiazunChen/CommunityAF\"\u003ehttps://github.com/JiazunChen/CommunityAF\u003c/a\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch1 id=\"reported-applications\"\u003eReported Applications\u003c/h1\u003e\n\u003cp\u003eRecommendation; Personal background discovery; Anomaly detection;\u003c/p\u003e","title":"Community Search Papers in Top Journals/Conferences"},{"content":" This is a collection of well-designed figures from research papers, complied for future reference in academic writing.\nNetwork Visualization Source: SEAL: Learning Heuristics for Community Detection with Generative Adversarial Networks\nSource: CommunityAF: An Example-Based Community Search Method via Autoregressive Flow\nSource: Scalable Community Search over Large-scale Graphs based on Graph Transformer\nSource: \u0026ldquo;A hierarchical overlapping community detection method based on closed trail distance and maximal cliques\u0026rdquo;\nFramework \u0026amp; Structure Source: \u0026ldquo;Local Community Detection: A Survey\u0026rdquo;\nSource: \u0026ldquo;Community Detection in Social Networks: An In-depth Benchmarking Study with a Procedure-Oriented Framework\u0026rdquo;\nColor Source: \u0026ldquo;Large Language Models Do Not Simulate Human Psychology\u0026rdquo;\nSource: \u0026ldquo;CommunityDF: A Guided Denoising Diffusion Approach for Community Search\u0026rdquo;\nSource: \u0026ldquo;Neural Attributed Community Search at Billion Scale\u0026rdquo;\nSource: \u0026ldquo;Cohesion in online environments\u0026rdquo;\n","permalink":"https://yningg.github.io/Blogs/posts/research/scientific_plotting/","summary":"\u003cblockquote\u003e\n\u003cp\u003eThis is a collection of well-designed figures from research papers, complied for future reference in academic writing.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2 id=\"network-visualization\"\u003eNetwork Visualization\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"alt text\" loading=\"lazy\" src=\"/Blogs/Figures/dblp_networks.png\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"alt text\" loading=\"lazy\" src=\"/Blogs/Figures/zhang2020seal.png\"\u003e\nSource: SEAL: Learning Heuristics for Community Detection with Generative Adversarial Networks\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"alt text\" loading=\"lazy\" src=\"/Blogs/Figures/cheng2023communityaf.png\"\u003e\u003c/p\u003e\n\u003cp\u003eSource: CommunityAF: An Example-Based Community Search Method via Autoregressive Flow\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"alt text\" loading=\"lazy\" src=\"/Blogs/Figures/wang2024scalable.png\"\u003e\nSource: Scalable Community Search over Large-scale Graphs based on Graph Transformer\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"alt text\" loading=\"lazy\" src=\"/Blogs/Figures/sl_ghac.png\"\u003e\nSource: \u003cem\u003e\u0026ldquo;A hierarchical overlapping community detection method based on closed trail distance and maximal cliques\u0026rdquo;\u003c/em\u003e\u003c/p\u003e","title":"Scientific Plotting"},{"content":" This is a collection of useful phrases and sentences from research papers for future reference in academic writing.\nPhrases \u0026amp; Sentences pave the way to…. be cognizant of a flurry of research hallmark (a hallmark of this paper) accentuate carve out with regard to/ pertaining to manifold scant attention has been given…\nwe focus on…., which is orthogonal to these efforts\nWhat is, surprisingly, missing to date is…\nHowever, traditional community detection algorithms fail to pinpoint a particular kind of community.\nThe motivation of this survey stems mainly from the fact that the literature for local community detection is scattered mainly between Physics and Computer Science and there is not a single point of entrance for a new researcher in this area.\nAny review of recent work examining cohesion, however, cannot overlook the definitional, measurement, and theoretical uncertainties that continue to dog this concept.\nObviously, interest in analyzing xxxx is a logical consequence of …., particularly in the context of ….., but it also offers the promise of a better understanding of ….\nWe will use these findings as a point of departure for a more in-depth analysis….\nConfirmation bias catalyzes the creation of ….\nOur grand vision is a pervasive desire to continue stimulating shifts in our traditional thinking by nudging the generation of data- and human-centric computing frameworks to be grounded on social and cognitive psychology.\nThese results figure into a diverse body of literature on channel effects and task performance.\nCultural diversity has long been recognized as a potential problem in the workplace that deserves serious attention. As far back as 1996, Fine stated that …\nNevertheless, we believe that given our research design and research question, the benefits of using a student sample outweigh the costs.\nAs more contenders emerged to lay claim to the most accurate definition of cohesion, single-factor definitions gave way to multicomponent models that suggested that cohesion has multiple facets.\nWe have no standard, off-the-shelf measure of cohesion in which we can have strong confidence.\nThe emergence of big data from social media has brought about a new wave of excitement in the field of artificial intelligence and data analytics.\nShapeSearch is a promising step towards accelerating the search for insights in data while catering to the needs of expert and novice programmers alike.\nTo close this research gap.\nOther Resources Sentence starters, transitional and other useful words https://www.phrasebank.manchester.ac.uk/ ","permalink":"https://yningg.github.io/Blogs/posts/research/phrases_sentences/","summary":"\u003cblockquote\u003e\n\u003cp\u003eThis is a collection of useful phrases and sentences from research papers for future reference in academic writing.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2 id=\"phrases--sentences\"\u003ePhrases \u0026amp; Sentences\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003epave the way to….\u003c/li\u003e\n\u003cli\u003ebe cognizant of\u003c/li\u003e\n\u003cli\u003ea flurry of research\u003c/li\u003e\n\u003cli\u003ehallmark (a hallmark of this paper)\u003c/li\u003e\n\u003cli\u003eaccentuate\u003c/li\u003e\n\u003cli\u003ecarve out\u003c/li\u003e\n\u003cli\u003ewith regard to/ pertaining to\u003c/li\u003e\n\u003cli\u003emanifold\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003escant attention\u003c/strong\u003e has been given…\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ewe focus on…., which \u003cstrong\u003eis orthogonal to\u003c/strong\u003e these efforts\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eWhat is, surprisingly, \u003cstrong\u003emissing to date\u003c/strong\u003e is…\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHowever, traditional community detection algorithms \u003cstrong\u003efail to pinpoint\u003c/strong\u003e a particular kind of community.\u003c/p\u003e","title":"Good Expressions/Sentences for Academic Writing"},{"content":"Literature Review V.S. Review Paper Literature Review Introduce research related to this specific study (usually in the introduction section) Shorter than standalone reviews. Narrower in scope Often used to set research precedent and support theory or methods Length: 2-4 paragraphs Standalone Review Articles Presents and analyzes as much relevant literature as possible to explain background and context. Broader in scope More extended analysis All sections refer to literature rather than to one current study Include conclusion section, which ties all of the work together, showing how the literature analysis contributes to the literature.\nHow many sources should be reviewed? Determined by the scope of the topic, the depth of analysis, and the extent of consensus or disagreement in this area.\nTips for Creating Strong (Literature) Review Clearly define your topic and audience first Read many literature reviews and articles Focus on more recent sources: using all the theories that have been found as fundamental and provide a stable foundation for work that hasn’t changed over the years Take notes while reading literature Literature Review Definition: An objective, concise, critical summary of published research literature relevant to a topic being researched in an article.\nA good Literature Review will… Order articles and books to focus on unresolved debates, inconsistencies, tensions, and questions in a research field. Summarize the most relevant aspects of scientific literature related to your area of research. Synthesize past and current research on the topic and show how your research fits in. What is included in the Literature Review Historical background: You should show what is written in this field, so that you can present something new and significant, and contribute to the understanding of this field, even in a small way. This also demonstrates to other researchers and journal editors that you know how to write theoretical concepts and put them in your own words to show your understanding. Current research context — questions, issues, debates, etc. This means discussing questions and debates in your field. You can contextualize your work by showing related work as historical background and current state of research, and showing the development and trend of the research. Relevant theories and concepts. Definition of relevant terminology to show how terms fit into the context of your work. Describe related research and show how your work expands or challenges this research, and work to fill in this gap. You can use the literature review to show what works, what doesn\u0026rsquo;t, and what\u0026rsquo;s missing. Supporting evidence for a practical problem/issue, and its importance. Review Articles A good review uses photographs, illustrations, graphs, and diagrams to aid the reader in understanding concepts, processes, or relationships being discussed.\nType of Review Narrative Review Articles: It can target a large group of audience (that may include non-experts or non-professionals) and hence is written in a comparatively easier format than systematic review articles Systematic Review Articles It mainly contains a lot more detail about a particular topic than narrative review articles. It is a comprehensive review of the original published research and is for a specific group of people because these articles contain an in-depth analysis of a particular topic, and this kind of paper is also known as a critical review paper. There are two types of systematic review articles, namely qualitative and quantitative reviews. Tutorial Review Articles These articles basically emphasize how to do stuff. Tutorial review papers explain how to prepare and achieve results with previously cited work and compare the methods in detail. Some examples of good review topic aspects Advance an important or new concept. In such a review, you summarize what is known and explain how this advances, modifies, or overturns a theory. Review the validity or applicability of a widely held view. Bring together different areas of research Evaluate a method Main Components Background Purpose Deliveries Challenges Gaps Correlation Inferences Directions Writing Process for both literature review \u0026amp; review articles Steps to follow Step 1: Choose a TOPIC — focus and explore this topic (At this point, you can adjust the scope of your article or literature review)\nTopic you are familiar with and interested in Topics that are current, well-established, and have ample research for review Topic your readers and other researchers will be interested in Step 2: RESEARCH — collect scholarly information and sources. The literature includes scholarly articles, books, dissertations/theses, and conference papers.\nStep 3: ANALYZE the network of information and SELECT the works + Use thought maps and charts to identify intersections of the research and outline important categories + Select the material most useful to your review\nStep 4: DESCRIBE and SUMMARIZE each selected article (Strip the summaries)\nWhen doing the background research, record the source of the information to allow others to validate what you said. This will lead to a sort of citation-details pairs that look like the following. Then you should split these information into two parts: the citations list and paragraphs containing information from the sources. (I think for the paragraphs, I\u0026rsquo;d better write it in my own languages.) Step 5: DEMONSTRATE how concepts in the literature relate to results of the study; ESTABLISH how the literature is connected.\nFor intro to a journal article: Identify the missing parts in previous studies that your study address. Highlight concepts that support your hypothesis, methods, results, or conclusions. For a stand-alone literature review: Highlight the concepts in each article and show how they strengthen a hypothesis or show a pattern. Identify unaddressed issues in previous studies. Identify what is accurate and what is out of scope within these works. Step 6: Focus on the connections between the literature and the current study or guiding concept/argument. Your hypothesis, argument, or guiding concept is GOLDEN THREAD!\nStep 6a. Re-order paragraphs\nRe-read all paragraph summaries Find similarities and differences Re-order paragraphs into logical list based on connections you find Notice: There will be no single correct way to re-arrange the paragraphs. The best is the one that you found effective.\nSome potential arrangements:\nCause-Effect Series of Advances Myths-Realities Problem-Solution Ancient-Modern Effective-Ineffective Step 6b. Combine paragraphs (If necessary)\nYou should decide which paragraph should stand alone as a paragraph, and which could be combined. Your decision would be based on two factors:\nHow closely related are the summaries? How long will the paragraph be? Try to limit to 10-14 lines. Sometimes, for instance, if you found there are three articles write the similar thing, but it is too long to combine them. You can combine part of them maybe as two paragraphs.\nStep 6c. Add topic sentences \u0026amp; Transitions. (This step is all about turning the summary paragraphs into the real paragraphs.) Step 6d: Add introduction \u0026amp; Conclusion Introduction: because the literature review summarize the published works by others, the thesis statement should bring together points discussed by the sources\n*Conclusion:\nOne common strategy for the conclusion is open with the re-statement of the thesis, which brings the readers back to the overall point. Another common strategy for the conclusion is to comment on any gaps or flaws in research reviewed. Precautions You need to be very careful about the logical order of a series of sentences from different citations. For example, is this paragraph stated around a certain point? And is there any relationship or transition between sentences? How to deal with the classical papers and the more recent papers? It is recommended that in each paragraph, start with the classical papers as the foundation of the statement, and end with more recent papers. And in such a single paragraph, try to present how this direction of research develops Referenced Sources https://www.bilibili.com/video/BV1eJ41167Ue?p=1 Include both an introduction on how to write a literature review for introducing and for a review paper. https://www.bilibili.com/video/BV1eJ41167Ue?p=2 Introduce 5 steps to actually compose a literature review, but still applies to the review paper. https://youtu.be/b72N-Qu7A90. It\u0026rsquo;s too broad, I only pick up something that I don\u0026rsquo;t know. https://youtu.be/bsoGBkf7mmE Also somewhat broad. https://youtu.be/kExJSYtv0ck Provide some suggestions about topic choosing. ","permalink":"https://yningg.github.io/Blogs/posts/research/literature_review/","summary":"\u003ch2 id=\"literature-review-vs-review-paper\"\u003eLiterature Review V.S. Review Paper\u003c/h2\u003e\n\u003ch3 id=\"literature-review\"\u003eLiterature Review\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eIntroduce research related to this specific study (usually in the introduction section)\u003c/li\u003e\n\u003cli\u003eShorter than standalone reviews.\u003c/li\u003e\n\u003cli\u003eNarrower in scope\u003c/li\u003e\n\u003cli\u003eOften used to set research precedent and support theory or methods\u003c/li\u003e\n\u003cli\u003eLength: 2-4 paragraphs\n\u003cimg alt=\"alt text\" loading=\"lazy\" src=\"/Blogs/Figures/literature_4.png\"\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"standalone-review-articles\"\u003eStandalone Review Articles\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003ePresents and analyzes as much relevant literature as possible to explain background and context.\u003c/li\u003e\n\u003cli\u003eBroader in scope\u003c/li\u003e\n\u003cli\u003eMore extended analysis\u003c/li\u003e\n\u003cli\u003eAll sections refer to literature rather than to one current study\u003c/li\u003e\n\u003c/ul\u003e\n\u003cblockquote\u003e\n\u003cp\u003eInclude conclusion section, which ties all of the work together, showing how the literature analysis contributes to the literature.\u003c/p\u003e","title":"How to Write a (Literature) Review"}]